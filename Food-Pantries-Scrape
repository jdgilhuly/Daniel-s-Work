#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jul  8 21:06:19 2020

@author: danielgilhuly
"""
#packages -- beautiful soup for the text/ selenium to navigate the page
from bs4 import BeautifulSoup as soup
from urllib.request import urlopen as uReq
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
import time
import pandas as pd
driver= webdriver.Chrome(ChromeDriverManager().install())

#Getting Links of the main foodpantries page
def getLinksOfMainPage(a):
    # getting urls and reading it
    my_url = a
    driver.get(my_url)
    uClient = uReq(my_url)
    page_html = uClient.read()
    uClient.close()
    page_soup = soup(page_html, "html.parser")
    
    #get links
    link_hold = []
    for link in page_soup.find_all('a'):
        link_hold.append(link.get('href'))
    
    #remove duplicates
    i = 1
    while i < len(link_hold):
        if link_hold[i] == link_hold[i-1]:
            del link_hold[i-1]
            i += 1
        else:
            i += 1
            
    return link_hold

# returns a list(url of regions) within a list(states)
def Individual_Links_to_States():
    all_region_links = []
    z = getLinksOfMainPage("https://www.foodpantries.org/")
    all_links = z[19:70] #get rid of non-state links
    for link in all_links:
        driver.get(link)
        all_region_links.append(getLinksOfMainPage(link))
        time.sleep(2)
        
    i = 0
    while i < len(all_region_links): #data cleaning
        all_region_links[i] = all_region_links[i][9:-8]
        i += 1
    return all_region_links


#names of individual food banks taking the link to the region page as its argument
def Get_Individual_Food_Banks(linktoStatePage):
    sauce = uReq(linktoStatePage)
    page_soup = soup(sauce,"lxml")
    FoodBankName = []
    temp2 = []
    combinedtemp = []
    
    for FoodBank in page_soup.find_all('h2'):
        FoodBankName.append(FoodBank.text)
    
    for items in page_soup.find_all('p'):
        temp2.append(items.text)
    
    i1 = 0
    i2 = 1
    while i1 < len(FoodBankName):
        combinedtemp.append(FoodBankName[i1]+ temp2[i2]+ temp2[i2+1])
        i1 += 1
        i2 += 2
    return combinedtemp

#Creates Dataset
def RunAll():
    States_List = Individual_Links_to_States()
    i1 = 0
    i2 = 0
    z1 = 0 #iterator of dataframe
    data = pd.DataFrame(columns = ["States", "City", "Zip-Code", "Food Bank Name", "Phone Number", "Descriptions"])
    while i1 < len(States_List): #i1 keeps track of the states
        data.loc[z1, "States"] = States_List[i1]
        while i2 < len(States_List[i1]): #i2 keeps track of the regions
            data.append(Get_Individual_Food_Banks(States_List[i1][i2]))
            i2 += 1
        i1 += 1
    return data

#Run to Test
DataSet = RunAll()

#To implement
#pandas dataset with iterator
#regex expressions
